{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klt8f7B4xBH8",
        "outputId": "c244c594-4f05-4330-eb6c-f97146642032"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tsfresh.feature_extraction import settings\n",
        "from tsfresh import extract_features\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "random_state = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FILENAME_CLIENTS = ''\n",
        "FILENAME_TRANSACTIONS = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH5qsB4wGaGt",
        "outputId": "deb95399-306f-425e-db29-b02c5f1c420c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-55-3e838caee14c>:1: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  db_client = pd.read_csv('/content/train_data/cntrbtrs_clnts_ops_trn.csv', encoding='cp1251', sep=';')\n"
          ]
        }
      ],
      "source": [
        "db_client = pd.read_csv(FILENAME_CLIENTS, encoding='cp1251', sep=';')\n",
        "db_check = pd.read_csv(FILENAME_TRANSACTIONS, encoding='cp1251', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOQrm66Qyqhd"
      },
      "outputs": [],
      "source": [
        "db_client.fillna({'okato': 65000000000.0}, inplace=True)\n",
        "db_client.fillna('', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkD1CdK9z39P"
      },
      "outputs": [],
      "source": [
        "def get_noth_region(data):\n",
        "    \"\"\"Создаём признак северного региона.\"\"\"\n",
        "\n",
        "    db = data.copy()\n",
        "\n",
        "    db['north_region'] = 0\n",
        "    db.loc[db.okato == 86000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 87000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 98000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 93000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 30000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 4000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 8000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 11000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 25000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 44000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 47000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 64000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 11100000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 77000000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 71140000000, 'north_region'] = 1\n",
        "    db.loc[db.okato == 71100000000, 'north_region'] = 1\n",
        "\n",
        "    db.north_region = db.north_region.astype('category')\n",
        "    return db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LODB2Nq6DL89"
      },
      "outputs": [],
      "source": [
        "def get_macro_feature(df_transactions):\n",
        "    '''\n",
        "    infl: https://xn----ctbjnaatncev9av3a8f8b.xn--p1ai/%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D1%8B-%D0%B8%D0%BD%D1%84%D0%BB%D1%8F%D1%86%D0%B8%D0%B8\n",
        "    GDP: https://gogov.ru/articles/vvp-rf\n",
        "    Безработица: https://infotables.ru/statistika/79-ekonomicheskaya-statistika-rossii/1021-uroven-bezrabotitsy-v-rossii\n",
        "    Естественный прирост: https://infotables.ru/statistika/31-rossijskaya-federatsiya/784-rozhdaemost-smertnost\n",
        "    infl, GDP (трлн. руб.), безработица, естественный прирост\n",
        "    '''\n",
        "\n",
        "    df_transactions = df_transactions[['accnt_id', 'oprtn_date', 'sum']].copy()\n",
        "    df_transactions['year'] = df_transactions.oprtn_date.apply(lambda x: x[:4])\n",
        "\n",
        "    macro = {'1999': [36.56, 4.823, 10.7, -6,15, 65.2],#\n",
        "         '2000': [20.2, 7.306, 10.6, -6.6, 65.3],#\n",
        "         '2001': [18.085, 9.73625, 9.9, -6.325, 65.2],#\n",
        "         '2002': [15.97, 12.1665, 9.2, -6.05, 65],#\n",
        "         '2003': [13.855, 14.59675, 8.5, -5.775, 64.9],#\n",
        "         '2004': [11.74, 17.027, 7.8, -5.5, 65.3],#\n",
        "         '2005': [10.91, 21.61, 7.1, -5.9, 65.4],#\n",
        "         '2006': [9, 26.917, 7.1, -4.8, 66.7],#\n",
        "         '2007': [11.87, 33.248, 6, -3.3, 67.6],#\n",
        "         '2008': [13.28, 41.277, 6.2, -2.5, 68],#\n",
        "         '2009': [8.8, 38.807, 8.3, -1.8, 68.8],#\n",
        "         '2010': [8.78, 46.309, 7.3, -1.7, 68.9],#\n",
        "         '2011': [6.1, 60.114, 6.5, -0.9, 69.83],#\n",
        "         '2012': [6.58, 68.103, 5.5, 0, 70.24],#\n",
        "         '2013': [6.45, 72.986, 5.5, 0.2, 70.76],#\n",
        "         '2014': [11.36, 79.03, 5.2, 0.2, 70.93],#\n",
        "         '2015': [12.91, 83.087, 5.6, 0.3, 71.39],#\n",
        "         '2016': [5.38, 86.043, 5.5, -0.01, 71.87],#\n",
        "         '2017': [2.52, 91.843, 5.2, -0.9, 72.7],\n",
        "         '2018': [4.27, 103.862, 4.8, -1.6, 72.91],\n",
        "         '2019': [3.05, 109.608, 4.6, -2.2, 73.34],\n",
        "         '2020': [4.91, 107.658, 5.8, -4.8, 71.54],\n",
        "         '2021': [8.39, 135.774, 4.8, -7.1, 70.06],\n",
        "         '2022': [11.92, 155.188, 3.9, -4, 72.73],\n",
        "         '2023': [7.42, 172.148, 3.2, -3, 73.41],\n",
        "         '2024': [7.42, 178.862, 3.1, -3, 73.6]}\n",
        "\n",
        "    df_transactions['infl'] = df_transactions.year.apply(lambda x: macro[x][0])\n",
        "    df_transactions['gpd'] = df_transactions.year.apply(lambda x: macro[x][1])\n",
        "    df_transactions['without_job'] = df_transactions.year.apply(lambda x: macro[x][2])\n",
        "    df_transactions['population_growth'] = df_transactions.year.apply(lambda x: macro[x][3])\n",
        "    df_transactions = df_transactions.drop(columns=['year'])\n",
        "\n",
        "    return df_transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERmjswaJDfBZ"
      },
      "outputs": [],
      "source": [
        "def get_time_series_feature(df_transactions):\n",
        "\n",
        "    setup = settings.MinimalFCParameters()\n",
        "\n",
        "    agg_transactions = extract_features(\n",
        "        df_transactions.copy(),\n",
        "        column_id='accnt_id',\n",
        "        column_sort='oprtn_date',\n",
        "        default_fc_parameters=setup,\n",
        "    )\n",
        "    agg_transactions = agg_transactions.reset_index(names='accnt_id')\n",
        "\n",
        "    return agg_transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QteGcL4uIjCx"
      },
      "outputs": [],
      "source": [
        "db_client = get_noth_region(db_client)\n",
        "db_check = get_macro_feature(db_check)\n",
        "agg_transactions = get_time_series_feature(db_check)\n",
        "\n",
        "df_clients = db_client.copy()\n",
        "df_clients = pd.merge(df_clients, agg_transactions, how=\"inner\", on=\"accnt_id\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90Ft7-hiF9oj"
      },
      "outputs": [],
      "source": [
        "df_clients.fillna({'okato': 65000000000.0}, inplace = True)\n",
        "df_clients.fillna('', inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9VCdUc9JJG9"
      },
      "outputs": [],
      "source": [
        "data0 = df_clients[df_clients['slctn_nmbr'] == 0]\n",
        "data1 = df_clients[df_clients['slctn_nmbr'] == 1]\n",
        "data2 = df_clients[df_clients['slctn_nmbr'] == 2]\n",
        "data3 = df_clients[df_clients['slctn_nmbr'] == 3]\n",
        "\n",
        "train0, val0 =  train_test_split(data0, test_size = 0.2, shuffle = True, random_state = random_state, stratify = data0['erly_pnsn_flg'])\n",
        "train1, val1 =  train_test_split(data1, test_size = 0.2, shuffle = True, random_state = random_state, stratify = data1['erly_pnsn_flg'])\n",
        "train2, val2 =  train_test_split(data2, test_size = 0.2, shuffle = True, random_state = random_state, stratify = data2['erly_pnsn_flg'])\n",
        "train3, val3 =  train_test_split(data3, test_size = 0.2, shuffle = True, random_state = random_state, stratify = data3['erly_pnsn_flg'])\n",
        "\n",
        "train_data = [\n",
        "   (train0, val0),\n",
        "   (train1, val1),\n",
        "   (train2, val2),\n",
        "   (train3, val3)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c2FbxnMJ6ER",
        "outputId": "65f987cc-fc52-4e02-c077-fca6e3375fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sum__sum_values', 'sum__median', 'sum__mean', 'sum__length', 'sum__standard_deviation', 'sum__variance', 'sum__root_mean_square', 'sum__maximum', 'sum__absolute_maximum', 'sum__minimum']\n",
            "f1, recall, acc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[99.5, 99.0, 99.99],\n",
              " [99.87, 99.8, 99.98],\n",
              " [99.58, 99.44, 99.94],\n",
              " [99.04, 98.23, 99.92]]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def total_model(train_data, agg_transactions):\n",
        "    \"\"\"Обучение pipeline на датасете.\"\"\"\n",
        "\n",
        "    cat = ['gndr', 'brth_yr', 'prsnt_age', 'pnsn_age', 'prvs_npf', 'okato', 'north_region']\n",
        "    num = agg_transactions.columns.to_list()[1:11]\n",
        "    print(num)\n",
        "\n",
        "    column_transformer = ColumnTransformer([\n",
        "        ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), cat),\n",
        "        ('scal', StandardScaler(), num)\n",
        "    ])\n",
        "\n",
        "\n",
        "    all_cls = []\n",
        "    pipes = []\n",
        "    score_models = []\n",
        "    for train, val in train_data:\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('ohe_scal', column_transformer),\n",
        "            ('cls', LogisticRegression())\n",
        "        ])\n",
        "\n",
        "        cls = pipe.fit(train[cat + num], train['erly_pnsn_flg'])\n",
        "\n",
        "        all_cls.append(cls)\n",
        "        pipes.append(pipe)\n",
        "        score_models.append(\n",
        "                [round(f1_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(recall_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(accuracy_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2)]\n",
        "                )\n",
        "\n",
        "    return all_cls, score_models, pipes\n",
        "\n",
        "\n",
        "all_cls, score_models, pipes = total_model(train_data, agg_transactions)\n",
        "print('f1, recall, acc')\n",
        "score_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvEKhRXK1HJZ",
        "outputId": "eb82c840-6861-4977-81f9-fac936c9af0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1, recall, acc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[98.48, 97.44, 99.96],\n",
              " [99.57, 99.41, 99.92],\n",
              " [99.37, 99.3, 99.91],\n",
              " [98.13, 96.86, 99.84]]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def total_model(train_data, agg_transactions):\n",
        "    cat = ['gndr', 'brth_yr', 'prvs_npf', 'okato', 'north_region']\n",
        "    num = agg_transactions.columns.to_list()[1:11]\n",
        "\n",
        "    column_transformer = ColumnTransformer([\n",
        "        ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), cat),\n",
        "        ('scal', StandardScaler(), num)\n",
        "    ])\n",
        "\n",
        "\n",
        "    all_cls = []\n",
        "    score_models = []\n",
        "    for train, val in train_data:\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('ohe_scal', column_transformer),\n",
        "            ('cls', LogisticRegression())\n",
        "        ])\n",
        "\n",
        "        cls = pipe.fit(train[cat + num], train['erly_pnsn_flg'])\n",
        "\n",
        "        all_cls.append(cls)\n",
        "\n",
        "        score_models.append(\n",
        "                [round(f1_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(recall_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(accuracy_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2)]\n",
        "                )\n",
        "\n",
        "    return all_cls, score_models\n",
        "\n",
        "\n",
        "\n",
        "all_cls, score_models = total_model(train_data, agg_transactions)\n",
        "print('f1, recall, acc')\n",
        "score_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sur7ldxo1jkA",
        "outputId": "7ab113bc-8a04-4560-de47-7291ec210f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1, recall, acc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[99.33, 99.0, 99.98],\n",
              " [99.8, 99.61, 99.96],\n",
              " [99.65, 99.44, 99.95],\n",
              " [99.18, 98.64, 99.93]]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def total_model(train_data, agg_transactions):\n",
        "    cat = ['gndr', 'brth_yr', 'pnsn_age', 'prvs_npf', 'okato', 'north_region']\n",
        "    num = agg_transactions.columns.to_list()[1:]\n",
        "\n",
        "    column_transformer = ColumnTransformer([\n",
        "        ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), cat),\n",
        "        ('scal', StandardScaler(), num)\n",
        "    ])\n",
        "\n",
        "\n",
        "    all_cls = []\n",
        "    score_models = []\n",
        "    for train, val in train_data:\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('ohe_scal', column_transformer),\n",
        "            ('cls', LogisticRegression())\n",
        "        ])\n",
        "\n",
        "        cls = pipe.fit(train[cat + num], train['erly_pnsn_flg'])\n",
        "\n",
        "        all_cls.append(cls)\n",
        "\n",
        "        score_models.append(\n",
        "                [round(f1_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(recall_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(accuracy_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2)]\n",
        "                )\n",
        "\n",
        "    return all_cls, score_models\n",
        "\n",
        "\n",
        "\n",
        "all_cls, score_models = total_model(train_data, agg_transactions)\n",
        "print('f1, recall, acc')\n",
        "score_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs0BzPCs1kfu",
        "outputId": "bfcd88b0-8a2f-466a-c923-8b8be3193ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1, recall, acc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[98.43, 97.77, 99.96],\n",
              " [99.38, 99.08, 99.88],\n",
              " [99.16, 98.89, 99.88],\n",
              " [98.34, 97.0, 99.86]]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def total_model(train_data, agg_transactions):\n",
        "    cat = ['gndr', 'brth_yr', 'prvs_npf', 'okato', 'north_region']\n",
        "    num = agg_transactions.columns.to_list()[1:]\n",
        "\n",
        "    column_transformer = ColumnTransformer([\n",
        "        ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), cat),\n",
        "        ('scal', StandardScaler(), num)\n",
        "    ])\n",
        "\n",
        "\n",
        "    all_cls = []\n",
        "    score_models = []\n",
        "    for train, val in train_data:\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('ohe_scal', column_transformer),\n",
        "            ('cls', LogisticRegression())\n",
        "        ])\n",
        "\n",
        "        cls = pipe.fit(train[cat + num], train['erly_pnsn_flg'])\n",
        "\n",
        "        all_cls.append(cls)\n",
        "\n",
        "        score_models.append(\n",
        "                [round(f1_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(recall_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "                round(accuracy_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2)]\n",
        "                )\n",
        "\n",
        "    return all_cls, score_models\n",
        "\n",
        "\n",
        "\n",
        "all_cls, score_models = total_model(train_data, agg_transactions)\n",
        "print('f1, recall, acc')\n",
        "score_models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtmd7-d73cfx"
      },
      "source": [
        "Для одной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVIZ6VPy3eaf"
      },
      "outputs": [],
      "source": [
        "train, val =  train_test_split(df_clients, test_size = 0.2, shuffle = True, random_state = random_state, stratify = df_clients['erly_pnsn_flg'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE36m5Zr4nWe",
        "outputId": "db7584d4-1676-4352-9364-1325a6c4872f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1, recall, acc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(99.43, 99.23, 99.96)"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cat = ['gndr', 'brth_yr', 'prsnt_age', 'pnsn_age', 'prvs_npf', 'okato', 'north_region']\n",
        "num = agg_transactions.columns.to_list()[1:11]\n",
        "\n",
        "column_transformer = ColumnTransformer([\n",
        "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), cat),\n",
        "    ('scal', StandardScaler(), num)\n",
        "])\n",
        "\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "    ('ohe_scal', column_transformer),\n",
        "    ('cls', LogisticRegression())\n",
        "])\n",
        "\n",
        "cls = pipe.fit(train[cat + num], train['erly_pnsn_flg'])\n",
        "\n",
        "\n",
        "score_model = (\n",
        "        round(f1_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "        round(recall_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2),\\\n",
        "        round(accuracy_score(val['erly_pnsn_flg'], cls.predict(val[cat + num])) * 100, 2)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "print('f1, recall, acc')\n",
        "score_model\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
